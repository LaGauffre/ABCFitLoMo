{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4.1\n",
    "\n",
    "Fit and model selection of a negative binomial-Weibull and negative binomial - gamma models on data simulated from a negative binomial -weibull data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ./preamble.py\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"PyMC3 version:\", pm.__version__)\n",
    "\n",
    "tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST = False\n",
    "\n",
    "# Processor information and SMC calibration parameters\n",
    "if not FAST:\n",
    "    numIters = 7\n",
    "    numItersData = 10\n",
    "    popSize = 1000\n",
    "    epsMin = 0\n",
    "    timeout = 1000\n",
    "else:\n",
    "    numIters = 3\n",
    "    numItersData = 8\n",
    "    popSize = 500\n",
    "    epsMin = 1\n",
    "    timeout = 30\n",
    "\n",
    "numProcs = 40\n",
    "smcArgs = {\"numProcs\": numProcs, \"timeout\": timeout, \"epsMin\": epsMin, \"verbose\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are are conducting a simulation experiment where the claim frequency are Negative Binomial distributed \n",
    "\n",
    "$$\n",
    "n_s\\underset{\\textbf{i.i.d.}}{\\sim}\\text{Neg-Bin}(\\alpha = 4, p = 2/3),\\text{ }s = 1,\\ldots, 30\n",
    "$$ \n",
    "\n",
    "and the individual claim sizes are weibull distributed\n",
    "\n",
    "$$\n",
    "u_1,\\ldots, u_{n_s}\\underset{\\textbf{i.i.d.}}{\\sim}\\text{Weib}(k = 1/3, \\beta = 1),\\text{ }s = 1,\\ldots 30.\n",
    "$$ \n",
    "\n",
    "The available data is aggregated claim sizes in excess of the priority $c=1$ asociated to aa global stop-loss treaty, we have \n",
    "\n",
    "$$\n",
    "x_s = \\left(\\sum_{k = 1}^{n_s}u_k-c\\right)_{+},\\text{ }s = 1,\\ldots, t.\n",
    "$$\n",
    "\n",
    "Our aim is to look into the finite sample performance of our ABC implementation when the model is well specified that is when we assume a negative binomial - weibull model\n",
    "\n",
    "# Inference of a Negative Binomial - Weibull model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = Generator(PCG64(123))\n",
    "\n",
    "sample_sizes = [50, 250]\n",
    "T = sample_sizes[-1]\n",
    "t = np.arange(1, T + 1, 1)\n",
    "\n",
    "# Frequency-Loss Model\n",
    "α, p, k, β = 4, 2 / 3, 1 / 3, 1\n",
    "θ_True = α, p, k, β\n",
    "θ_sev = k, β\n",
    "θ_freq = α, p\n",
    "freq = \"negative binomial\"\n",
    "sev = \"weibull\"\n",
    "\n",
    "# Aggregation process\n",
    "c = 1\n",
    "psi = abcre.Psi(\"GSL\", c)\n",
    "\n",
    "freqs, sevs = abcre.simulate_claim_data(rg, T, freq, sev, θ_True)\n",
    "df_full = pd.DataFrame(\n",
    "    {\n",
    "        \"time_period\": np.concatenate([np.repeat(s, freqs[s - 1]) for s in t]),\n",
    "        \"claim_size\": sevs,\n",
    "    }\n",
    ")\n",
    "\n",
    "xData = abcre.compute_psi(freqs, sevs, psi)\n",
    "\n",
    "df_agg = pd.DataFrame({\"time_period\": t, \"N\": freqs, \"X\": xData})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.sum(xData[:ss] > 0) for ss in sample_sizes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True posterior samples\n",
    "\n",
    "We run a Bayesian analysis on the individual claim data and frequency data so as to infer the parameters of the Weibull, distribution. The prior distribution on the parameters are taken as independent uniform distribution (as in the ABC approach). \n",
    "\n",
    "### Fitting a Weibull model to the individual loss data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsev = pd.DataFrame({\"ss\": [], \"k\": [], \"β\": []})\n",
    "\n",
    "for ss in sample_sizes:\n",
    "\n",
    "    uData = np.array(df_full.claim_size[df_full.time_period <= ss])\n",
    "    print(\"The number of individual claim sizes is \", len(uData))\n",
    "\n",
    "    with pm.Model() as model_weib:\n",
    "        k = pm.Uniform(\"k\", lower=1e-1, upper=10)\n",
    "        β = pm.Uniform(\"β\", lower=0, upper=20)\n",
    "        X = pm.Weibull(\"X\", alpha=k, beta=β, observed=uData)\n",
    "\n",
    "        %time trace = pm.sample_smc(popSize, random_seed=1)\n",
    "        pm.plot_posterior(trace)\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        {\"ss\": np.repeat(ss, popSize), \"k\": trace[\"k\"], \"β\": trace[\"β\"],}\n",
    "    )\n",
    "    dfsev = pd.concat([dfsev, res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABC posterior sample of a negative binomial - Weibull model\n",
    "### ABC posterior sample of a negative binomial - Weibull model without the claim counts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (\"α\", \"p\", \"k\", \"β\")\n",
    "prior = abcre.IndependentUniformPrior([(0, 10), (1e-3, 1), (1e-1, 10), (0, 20)], params)\n",
    "model = abcre.Model(\"negative binomial\", \"weibull\", psi, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfABC = pd.DataFrame({\"ss\": [], \"weights\": [], \"α\": [], \"p\": [], \"r\": [], \"m\": []})\n",
    "\n",
    "for ss in sample_sizes:\n",
    "    xDataSS = df_agg.X[df_agg.time_period <= ss].to_numpy()\n",
    "\n",
    "    %time fit = abcre.smc(numIters, popSize, xDataSS, model, **smcArgs)\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        {\n",
    "            \"ss\": np.repeat(ss, popSize),\n",
    "            \"weights\": fit.weights,\n",
    "            \"α\": fit.samples[:, 0],\n",
    "            \"p\": fit.samples[:, 1],\n",
    "            \"k\": fit.samples[:, 2],\n",
    "            \"β\": fit.samples[:, 3],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    dfABC = pd.concat([dfABC, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(params), tight_layout=True)\n",
    "\n",
    "for l in range(len(params)):\n",
    "    pLims = [prior.marginals[l].isf(1), prior.marginals[l].isf(0)]\n",
    "\n",
    "    for k, ss in enumerate(sample_sizes):\n",
    "        sampleData = dfABC.query(\"ss == @ss\")\n",
    "        sample = sampleData[params[l]]\n",
    "        weights = sampleData[\"weights\"]\n",
    "\n",
    "        dataResampled, xs, ys = abcre.resample_and_kde(sample, weights, clip=pLims)\n",
    "        axs[l].plot(xs, ys, label=\"ABC\")\n",
    "        axs[l].axvline(θ_True[l], **trueStyle)\n",
    "        # axs[l].set_title(\"$\" + params[l] + \"$\")\n",
    "        axs[l].set_yticks([])\n",
    "\n",
    "draw_prior(prior, axs)\n",
    "sns.despine(left=True)\n",
    "# save_cropped(\"../Figures/hist-test1-negbin-weib.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABC posterior sample of a negative binomial - Weibull model with the claim counts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (\"k\", \"β\")\n",
    "prior = abcre.IndependentUniformPrior([(1e-1, 10), (0, 20)], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfABC_freq = pd.DataFrame({\"ss\": [], \"weights\": [], \"k\": [], \"β\": []})\n",
    "\n",
    "for ss in sample_sizes:\n",
    "    xDataSS = df_agg.X[df_agg.time_period <= ss].to_numpy()\n",
    "    nData = np.array(df_agg.N[df_agg.time_period <= ss])\n",
    "\n",
    "    model = abcre.Model(nData, \"weibull\", psi, prior)\n",
    "\n",
    "    %time fit = abcre.smc(numItersData, popSize, xDataSS, model, **smcArgs)\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        {\n",
    "            \"ss\": np.repeat(ss, popSize),\n",
    "            \"weights\": fit.weights,\n",
    "            \"k\": fit.samples[:, 0],\n",
    "            \"β\": fit.samples[:, 1],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    dfABC_freq = pd.concat([dfABC_freq, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(params), tight_layout=True)\n",
    "\n",
    "alphas = (0.6, 1)\n",
    "\n",
    "for l in range(len(params)):\n",
    "    pLims = [prior.marginals[l].isf(1), prior.marginals[l].isf(0)]\n",
    "\n",
    "    axs[l].axvline(θ_True[l + 2], **trueStyle)\n",
    "    axs[l].set_yticks([])\n",
    "    for k, ss in enumerate(sample_sizes):\n",
    "\n",
    "        for j, df in enumerate((dfABC, dfABC_freq)):\n",
    "            sampleData = df.query(\"ss == @ss\")\n",
    "            sample = sampleData[params[l]]\n",
    "            weights = sampleData[\"weights\"]\n",
    "\n",
    "            dataResampled, xs, ys = abcre.resample_and_kde(sample, weights, clip=pLims)\n",
    "            axs[l].plot(xs, ys, label=\"ABC\", alpha=alphas[j], c=colors[k])\n",
    "\n",
    "            # axs[l].set_title(\"$\" + params[l] + \"$\")\n",
    "\n",
    "sns.despine(left=True)\n",
    "# save_cropped(\"../Figures/hist-test1-negbin-weib-both.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABC posterior sample of a negative binomial - Gamma model\n",
    "### Maximum likelihood estimator as target for ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = Generator(PCG64(123))\n",
    "%run -i ./infer_loss_distribution.py\n",
    "uData_10000 = abcre.simulate_claim_sizes(rg, 10000, sev, θ_sev)\n",
    "r_mle, m_mle, BIC = infer_gamma(uData_10000, [1, 1])\n",
    "\n",
    "θ_plot = [α, p, np.NaN, np.NaN]\n",
    "θ_mle = [np.NaN, np.NaN, r_mle, m_mle]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC posterior of the gamma model based on the individual claim sizes data and the negative binomial distribution based on the claim counts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsev = pd.DataFrame({\"ss\": [], \"r\": [], \"m\": []})\n",
    "\n",
    "for ss in sample_sizes:\n",
    "\n",
    "    uData = np.array(df_full.claim_size[df_full.time_period <= ss])\n",
    "    print(\"The number of individual claim sizes is \", len(uData))\n",
    "\n",
    "    # We fit a gamma model using SMC\n",
    "    with pm.Model() as model_gamma:\n",
    "        r = pm.Uniform(\"r\", lower=0, upper=10)\n",
    "        m = pm.Uniform(\"m\", lower=0, upper=50)\n",
    "\n",
    "        X = pm.Gamma(\"X\", alpha=r, beta=1 / m, observed=uData)\n",
    "        %time trace = pm.sample_smc(popSize, random_seed=1)\n",
    "        pm.plot_posterior(trace)\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        {\"ss\": np.repeat(ss, popSize), \"r\": trace[\"r\"], \"m\": trace[\"m\"],}\n",
    "    )\n",
    "    dfsev = pd.concat([dfsev, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffreq = pd.DataFrame({\"ss\": [], \"α\": [], \"p\": []})\n",
    "\n",
    "for ss in sample_sizes:\n",
    "    nData = df_agg.N[df_agg.time_period <= ss]\n",
    "    with pm.Model() as model_negbin:\n",
    "        α = pm.Uniform(\"α\", lower=0, upper=10)\n",
    "        p = pm.Uniform(\"p\", lower=1e-3, upper=1)\n",
    "        N = pm.NegativeBinomial(\"N\", mu=α * (1 - p) / p, alpha=α, observed=nData)\n",
    "\n",
    "        %time trace = pm.sample_smc(popSize, random_seed=1)\n",
    "        pm.plot_posterior(trace)\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        {\"ss\": np.repeat(ss, popSize), \"α\": trace[\"α\"], \"p\": trace[\"p\"],}\n",
    "    )\n",
    "    dffreq = pd.concat([dffreq, res])\n",
    "dftrue = pd.concat([dffreq, dfsev.drop(\"ss\", axis=1)], axis=1)\n",
    "dftrue[\"posterior\"] = np.repeat(\"True\", len(dftrue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABC posterior sample of a negative binomial - Gamma model without the claim counts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (\"α\", \"p\", \"r\", \"m\")\n",
    "prior = abcre.IndependentUniformPrior([(0, 10), (1e-3, 1), (0, 10), (0, 50)], params)\n",
    "model = abcre.Model(\"negative binomial\", \"gamma\", psi, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "dfABC = pd.DataFrame({'ss':[],'weights':[],'α':[],'p':[],'r':[],'m':[]})\n",
    "\n",
    "for ss in sample_sizes:\n",
    "    xDataSS = df_agg.X[df_agg.time_period <= ss].to_numpy()\n",
    "\n",
    "    %time fit = abcre.smc(numIters, popSize, xDataSS, model, **smcArgs)\n",
    "\n",
    "    res = pd.DataFrame({'ss':np.repeat(ss, popSize),\n",
    "                                     'weights': fit.weights,\n",
    "                                     'α': fit.samples[:,0],\n",
    "                                     'p': fit.samples[:,1],\n",
    "                                     'r': fit.samples[:,2],\n",
    "                                     'm': fit.samples[:,3]})\n",
    "\n",
    "    dfABC = pd.concat([dfABC, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(params), tight_layout=True)\n",
    "\n",
    "for l in range(len(params)):\n",
    "    pLims = [prior.marginals[l].isf(1), prior.marginals[l].isf(0)]\n",
    "\n",
    "    for k, ss in enumerate(sample_sizes):\n",
    "        sampleData = dfABC.query(\"ss == @ss\")\n",
    "        sample = sampleData[params[l]]\n",
    "        weights = sampleData[\"weights\"]\n",
    "\n",
    "        dataResampled, xs, ys = abcre.resample_and_kde(sample, weights, clip=pLims)\n",
    "        axs[l].plot(xs, ys, label=\"ABC\")\n",
    "\n",
    "    axs[l].axvline(θ_plot[l], **trueStyle)\n",
    "    axs[l].axvline(θ_mle[l], **mleStyle)\n",
    "    # axs[l].set_title(\"$\" + params[l] + \"$\")\n",
    "    axs[l].set_yticks([])\n",
    "\n",
    "draw_prior(prior, axs)\n",
    "sns.despine(left=True)\n",
    "# save_cropped(\"../Figures/hist-test1-negbin-gamma.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABC posterior sample of a negative binomial - Gamma model with the claim counts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (\"r\", \"m\")\n",
    "prior = abcre.IndependentUniformPrior([(0, 10), (0, 50)], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfABC_freq = pd.DataFrame({\"ss\": [], \"weights\": [], \"r\": [], \"m\": []})\n",
    "\n",
    "for ss in sample_sizes:\n",
    "    xDataSS = df_agg.X[df_agg.time_period <= ss].to_numpy()\n",
    "    nData = np.array(df_agg.N[df_agg.time_period <= ss])\n",
    "\n",
    "    model = abcre.Model(nData, \"gamma\", psi, prior)\n",
    "\n",
    "    %time fit = abcre.smc(numItersData, popSize, xDataSS, model, **smcArgs)\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        {\n",
    "            \"ss\": np.repeat(ss, popSize),\n",
    "            \"weights\": fit.weights,\n",
    "            \"r\": fit.samples[:, 0],\n",
    "            \"m\": fit.samples[:, 1],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    dfABC_freq = pd.concat([dfABC_freq, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(params), tight_layout=True)\n",
    "\n",
    "alphas = (0.6, 1)\n",
    "\n",
    "for l in range(len(params)):\n",
    "    pLims = [prior.marginals[l].isf(1), prior.marginals[l].isf(0)]\n",
    "\n",
    "    axs[l].axvline(θ_mle[l + 2], **mleStyle)\n",
    "    axs[l].set_yticks([])\n",
    "    for k, ss in enumerate(sample_sizes):\n",
    "\n",
    "        for j, df in enumerate((dfABC, dfABC_freq)):\n",
    "            sampleData = df.query(\"ss == @ss\")\n",
    "            sample = sampleData[params[l]]\n",
    "            weights = sampleData[\"weights\"]\n",
    "\n",
    "            dataResampled, xs, ys = abcre.resample_and_kde(sample, weights, clip=pLims)\n",
    "            axs[l].plot(xs, ys, label=\"ABC\", alpha=alphas[j], c=colors[k])\n",
    "\n",
    "            # axs[l].set_title(\"$\" + params[l] + \"$\")\n",
    "\n",
    "sns.despine(left=True)\n",
    "# save_cropped(\"../Figures/hist-test1-negbin-gamma-both.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection between gamma and Weibull for the claim sizes\n",
    "### SMC model probabilities based on the individual claim sizes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayesian_Summary = pd.DataFrame({\"model\": [], \"ss\": [], \"k\": [], \"β\": []})\n",
    "models = [\"True weibull\", \"True gamma\"]\n",
    "for m in models:\n",
    "    for ss in sample_sizes:\n",
    "\n",
    "        uData = np.array(df_full.claim_size[df_full.time_period <= ss])\n",
    "        print(\"The number of individual claim sizes is \", len(uData))\n",
    "        if m == \"True weibull\":\n",
    "            # We fit a Weibull model using SMC\n",
    "            with pm.Model() as model_sev:\n",
    "                k = pm.Uniform(\"k\", lower=1e-1, upper=10)\n",
    "                β = pm.Uniform(\"β\", lower=0, upper=20)\n",
    "                U = pm.Weibull(\"U\", alpha=k, beta=β, observed=uData)\n",
    "                %time trace = pm.sample_smc(popSize, random_seed=1)\n",
    "\n",
    "        elif m == \"True gamma\":\n",
    "            # We fit a gamma model using SMC\n",
    "            with pm.Model() as model_sev:\n",
    "                param1 = pm.Uniform(\"k\", lower=0, upper=10)\n",
    "                param2 = pm.Uniform(\"β\", lower=0, upper=50)\n",
    "                U = pm.Gamma(\"U\", alpha=param1, beta=1 / param2, observed=uData)\n",
    "                %time trace = pm.sample_smc(popSize, random_seed=1)\n",
    "\n",
    "        pm.plot_posterior(trace)\n",
    "\n",
    "        log_lik = model_sev.marginal_log_likelihood\n",
    "\n",
    "        res = pd.DataFrame(\n",
    "            {\n",
    "                \"model\": [m],\n",
    "                \"ss\": [ss],\n",
    "                \"k\": [trace[\"k\"].mean()],\n",
    "                \"β\": [trace[\"β\"].mean()],\n",
    "                \"marginal_log_likelihood\": [log_lik],\n",
    "            }\n",
    "        )\n",
    "        Bayesian_Summary = pd.concat([Bayesian_Summary, res])\n",
    "\n",
    "max_marginal_log_likelihood = (\n",
    "    Bayesian_Summary[[\"ss\", \"marginal_log_likelihood\"]]\n",
    "    .groupby(\"ss\")\n",
    "    .max()\n",
    "    .marginal_log_likelihood.values\n",
    ")\n",
    "max_marginal_log_likelihood = np.concatenate(\n",
    "    [max_marginal_log_likelihood, max_marginal_log_likelihood]\n",
    ")\n",
    "Bayesian_Summary[\"BF\"] = np.exp(\n",
    "    Bayesian_Summary.marginal_log_likelihood - max_marginal_log_likelihood\n",
    ")\n",
    "sum_BF = Bayesian_Summary[[\"ss\", \"BF\"]].groupby(\"ss\").sum().BF.values\n",
    "sum_BF = np.concatenate([sum_BF, sum_BF])\n",
    "Bayesian_Summary[\"model_probability\"] = Bayesian_Summary.BF / sum_BF\n",
    "Bayesian_Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABC posterior for choosing between Weibull and gamma to model the claim sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST = True\n",
    "\n",
    "# Processor information and SMC calibration parameters\n",
    "if not FAST:\n",
    "    numIters = 7\n",
    "    numItersData = 10\n",
    "    popSize = 1000\n",
    "    popSizeModels = 1000\n",
    "    epsMin = 0\n",
    "    timeout = 1000\n",
    "else:\n",
    "    numIters = 4\n",
    "    numItersData = 8\n",
    "    popSize = 500\n",
    "    popSizeModels = 1000\n",
    "    epsMin = 1\n",
    "    timeout = 30\n",
    "\n",
    "numProcs = 40\n",
    "smcArgs = {\"numProcs\": numProcs, \"timeout\": timeout, \"epsMin\": epsMin, \"verbose\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABC model probabilities without the claim frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ((\"α\", \"p\", \"k\", \"β\"), (\"α\", \"p\", \"r\", \"m\"))\n",
    "\n",
    "prior1 = abcre.IndependentUniformPrior(\n",
    "    [(0, 20), (1e-3, 1), (1e-1, 10), (0, 20)], params[0]\n",
    ")\n",
    "model1 = abcre.Model(\"negative binomial\", \"weibull\", psi, prior1)\n",
    "\n",
    "prior2 = abcre.IndependentUniformPrior(\n",
    "    [(0, 20), (1e-3, 1), (1e-1, 10), (0, 50)], params[1]\n",
    ")\n",
    "model2 = abcre.Model(\"negative binomial\", \"gamma\", psi, prior2)\n",
    "\n",
    "models = [model1, model2]\n",
    "model_names = [\"ABC negative binomial - weibull\", \"ABC negative binomial - gamma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_proba_abc = pd.DataFrame({\"model\": [], \"ss\": [], \"model_probability\": []})\n",
    "dfabc = pd.DataFrame(\n",
    "    {\"model\": [], \"ss\": [], \"weights\": [], \"α\": [], \"p\": [], \"param1\": [], \"param2\": []}\n",
    ")\n",
    "\n",
    "for ss in sample_sizes:\n",
    "    xDataSS = df_agg.X[df_agg.time_period <= ss].values\n",
    "\n",
    "    %time fit = abcre.smc(numIters, popSizeModels, xDataSS, models, **smcArgs)\n",
    "\n",
    "    for k in range(len(models)):\n",
    "        weights = fit.weights[fit.models == k]\n",
    "        res_mp = pd.DataFrame(\n",
    "            {\n",
    "                \"model\": pd.Series([model_names[k]]),\n",
    "                \"ss\": np.array([ss]),\n",
    "                \"model_probability\": pd.Series(np.sum(fit.weights[fit.models == k])),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        model_proba_abc = pd.concat([model_proba_abc, res_mp])\n",
    "\n",
    "        res_post_samples = pd.DataFrame(\n",
    "            {\n",
    "                \"model\": np.repeat(model_names[k], len(weights)),\n",
    "                \"ss\": np.repeat(ss, len(weights)),\n",
    "                \"weights\": weights / np.sum(weights),\n",
    "                \"α\": np.array(fit.samples)[fit.models == k, 0],\n",
    "                \"p\": np.array(fit.samples)[fit.models == k, 1],\n",
    "                \"param1\": np.array(fit.samples)[fit.models == k, 2],\n",
    "                \"param2\": np.array(fit.samples)[fit.models == k, 3],\n",
    "            }\n",
    "        )\n",
    "        dfabc = pd.concat([dfabc, res_post_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABC model probabilities with the claim frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ((\"k\", \"β\"), (\"r\", \"m\"))\n",
    "\n",
    "prior1 = abcre.IndependentUniformPrior([(1e-1, 10), (0, 20)], params[0])\n",
    "prior2 = abcre.IndependentUniformPrior([(0, 10), (0, 50)], params[1])\n",
    "\n",
    "model_names = (\"ABC with freqs - weibull\", \"ABC with freqs - gamma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_proba_abc_freq = pd.DataFrame({\"model\": [], \"ss\": [], \"model_probability\": []})\n",
    "dfabc_freq = pd.DataFrame(\n",
    "    {\"model\": [], \"ss\": [], \"weights\": [], \"param1\": [], \"param2\": []}\n",
    ")\n",
    "\n",
    "for ss in sample_sizes:\n",
    "    xDataSS = df_agg.X[df_agg.time_period <= ss].values\n",
    "    nData = df_agg.N[df_agg.time_period <= ss].values\n",
    "\n",
    "    model1 = abcre.Model(nData, \"weibull\", psi, prior1)\n",
    "    model2 = abcre.Model(nData, \"gamma\", psi, prior2)\n",
    "    models = [model1, model2]\n",
    "\n",
    "    %time fit = abcre.smc(numItersData, popSizeModels, xDataSS, models, **smcArgs)\n",
    "\n",
    "    for k in range(len(models)):\n",
    "        weights = fit.weights[fit.models == k]\n",
    "        res_mp = pd.DataFrame(\n",
    "            {\n",
    "                \"model\": pd.Series([model_names[k]]),\n",
    "                \"ss\": np.array([ss]),\n",
    "                \"model_probability\": pd.Series(np.sum(fit.weights[fit.models == k])),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        model_proba_abc_freq = pd.concat([model_proba_abc_freq, res_mp])\n",
    "\n",
    "        res_post_samples = pd.DataFrame(\n",
    "            {\n",
    "                \"model\": np.repeat(model_names[k], len(weights)),\n",
    "                \"ss\": np.repeat(ss, len(weights)),\n",
    "                \"weights\": weights / np.sum(weights),\n",
    "                \"param1\": np.array(fit.samples)[fit.models == k, 0],\n",
    "                \"param2\": np.array(fit.samples)[fit.models == k, 1],\n",
    "            }\n",
    "        )\n",
    "        dfabc_freq = pd.concat([dfabc_freq, res_post_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_proba_df = pd.concat(\n",
    "    [\n",
    "        Bayesian_Summary[[\"model\", \"ss\", \"model_probability\"]],\n",
    "        model_proba_abc,\n",
    "        model_proba_abc_freq,\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    pd.pivot_table(\n",
    "        model_proba_df,\n",
    "        values=\"model_probability\",\n",
    "        index=[\"ss\"],\n",
    "        columns=[\"model\"],\n",
    "        aggfunc=np.sum,\n",
    "    ).to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
