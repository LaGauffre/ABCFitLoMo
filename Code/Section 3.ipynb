{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3\n",
    "\n",
    "Model selection from lognormal, gamma and weibull when the data is lognormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ./preamble.py\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"PyMC3 version:\", pm.__version__)\n",
    "\n",
    "tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST = False\n",
    "\n",
    "# Processor information and SMC calibration parameters\n",
    "if not FAST:\n",
    "    numItersData = 25\n",
    "    popSize = 1000\n",
    "    popSizeModels = 1000\n",
    "    epsMin = 0\n",
    "    timeout = 1000\n",
    "else:\n",
    "    numItersData = 3\n",
    "    popSize = 500\n",
    "    popSizeModels = 1000\n",
    "    epsMin = 1\n",
    "    timeout = 30\n",
    "\n",
    "numProcs = 4\n",
    "smcArgs = {\"numProcs\": numProcs, \"timeout\": timeout, \"epsMin\": epsMin, \"verbose\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of claim data for all three models, though we only consider the lognormal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import gamma\n",
    "\n",
    "rg = Generator(PCG64(123))\n",
    "\n",
    "T = 200\n",
    "sample_sizes = [25, 50, 75, 100, 150, 200]\n",
    "\n",
    "claim_data = pd.DataFrame(\n",
    "    {\n",
    "        \"lognormal\": abcre.simulate_claim_sizes(rg, T, \"lognormal\", (0, 1)),\n",
    "        \"gamma\": abcre.simulate_claim_sizes(rg, T, \"gamma\", (np.exp(1 / 2), 1)),\n",
    "        \"weibull\": abcre.simulate_claim_sizes(\n",
    "            rg, T, \"weibull\", (1 / 2, np.exp(1 / 2) / gamma(3 / 2))\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABC model probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_data = [\"lognormal\"]\n",
    "models_fitted = [\"gamma\", \"lognormal\", \"weibull\"]\n",
    "\n",
    "priorG = abcre.IndependentUniformPrior([(0, 5), (0, 100)], (\"r\", \"m\"))\n",
    "modelG = abcre.Model(sev=\"gamma\", prior=priorG)\n",
    "\n",
    "priorL = abcre.IndependentUniformPrior([(-20, 20), (0, 5)], (\"μ\", \"σ\"))\n",
    "modelL = abcre.Model(sev=\"lognormal\", prior=priorL)\n",
    "\n",
    "priorW = abcre.IndependentUniformPrior([(1e-1, 5), (0, 100)], (\"k\", \"δ\"))\n",
    "modelW = abcre.Model(sev=\"weibull\", prior=priorW)\n",
    "\n",
    "models = [modelG, modelL, modelW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_proba_abc = pd.DataFrame(\n",
    "    {\"model_data\": [], \"model_fit\": [], \"ss\": [], \"model_probability_ABC\": []}\n",
    ")\n",
    "\n",
    "# model_data = \"lognormal\"\n",
    "for model_data in models_data:\n",
    "    sevs = claim_data[model_data]\n",
    "    for ss in sample_sizes:\n",
    "        uData = sevs[:ss]\n",
    "        %time fit = abcre.smc(numItersData, popSizeModels, uData, models, **smcArgs)\n",
    "        for k in range(len(models)):\n",
    "            weights = fit.weights[fit.models == k]\n",
    "            res_mp = pd.DataFrame(\n",
    "                {\n",
    "                    \"model_data\": pd.Series(model_data),\n",
    "                    \"model_fit\": pd.Series([models_fitted[k]]),\n",
    "                    \"ss\": np.array([ss]),\n",
    "                    \"model_probability_ABC\": pd.Series(\n",
    "                        np.sum(fit.weights[fit.models == k])\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "            model_proba_abc = pd.concat([model_proba_abc, res_mp])\n",
    "            model_proba_abc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMC model probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayesian_Summary = pd.DataFrame(\n",
    "    {\n",
    "        \"model_data\": [],\n",
    "        \"model_fit\": [],\n",
    "        \"ss\": [],\n",
    "        \"param_1\": [],\n",
    "        \"param_2\": [],\n",
    "        \"marginal_log_likelihood\": [],\n",
    "    }\n",
    ")\n",
    "\n",
    "for model_data in models_data:\n",
    "    sevs = claim_data[model_data]\n",
    "    for model_fitted in models_fitted:\n",
    "\n",
    "        for ss in sample_sizes:\n",
    "            uData = sevs[:ss]\n",
    "            print(\n",
    "                f\"Fitting a {model_fitted} model to {len(uData)} data points generated from a {model_data} model\"\n",
    "            )\n",
    "\n",
    "            if model_fitted == \"gamma\":\n",
    "                with pm.Model() as model_sev:\n",
    "                    r = pm.Uniform(\"param_1\", lower=0, upper=5)\n",
    "                    m = pm.Uniform(\"param_2\", lower=0, upper=100)\n",
    "                    U = pm.Gamma(\"U\", alpha=r, beta=1 / m, observed=uData)\n",
    "                    %time trace = pm.sample_smc(popSize, random_seed=1)\n",
    "\n",
    "            elif model_fitted == \"lognormal\":\n",
    "                with pm.Model() as model_sev:\n",
    "                    μ = pm.Uniform(\"param_1\", lower=-20, upper=20)\n",
    "                    σ = pm.Uniform(\"param_2\", lower=0, upper=5)\n",
    "                    U = pm.Lognormal(\"U\", mu=μ, sigma=σ, observed=uData)\n",
    "                    %time trace = pm.sample_smc(popSize, random_seed=1)\n",
    "\n",
    "            elif model_fitted == \"weibull\":\n",
    "                with pm.Model() as model_sev:\n",
    "                    k = pm.Uniform(\"param_1\", lower=1e-1, upper=5)\n",
    "                    δ = pm.Uniform(\"param_2\", lower=0, upper=100)\n",
    "                    U = pm.Weibull(\"U\", alpha=k, beta=δ, observed=uData)\n",
    "                    %time trace = pm.sample_smc(popSize, random_seed=1)\n",
    "\n",
    "            # pm.plot_posterior(trace)\n",
    "\n",
    "            ll = model_sev.marginal_log_likelihood\n",
    "\n",
    "            res = pd.DataFrame(\n",
    "                {\n",
    "                    \"model_data\": [model_data],\n",
    "                    \"model_fit\": [model_fitted],\n",
    "                    \"ss\": [ss],\n",
    "                    \"param_1\": [trace[\"param_1\"].mean()],\n",
    "                    \"param_2\": [trace[\"param_2\"].mean()],\n",
    "                    \"marginal_log_likelihood\": [ll],\n",
    "                }\n",
    "            )\n",
    "            Bayesian_Summary = pd.concat([Bayesian_Summary, res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_marginal_log_likelihood = (\n",
    "    Bayesian_Summary[[\"model_data\", \"ss\", \"marginal_log_likelihood\"]]\n",
    "    .groupby([\"model_data\", \"ss\"])\n",
    "    .max()\n",
    ")\n",
    "max_marginal_log_likelihood.reset_index(level=[\"model_data\", \"ss\"], inplace=True)\n",
    "max_marginal_log_likelihood.rename(\n",
    "    columns={\"marginal_log_likelihood\": \"max_marginal_log_likelihood\"}\n",
    ")\n",
    "\n",
    "Bayesian_Summary_1 = pd.merge(\n",
    "    Bayesian_Summary, max_marginal_log_likelihood, how=\"left\", on=[\"model_data\", \"ss\"]\n",
    ")\n",
    "Bayesian_Summary_1\n",
    "\n",
    "Bayesian_Summary_1[\"BF\"] = np.exp(\n",
    "    Bayesian_Summary_1.marginal_log_likelihood_x\n",
    "    - Bayesian_Summary_1.marginal_log_likelihood_y\n",
    ")\n",
    "\n",
    "Bayesian_Summary_1\n",
    "sum_BF = (\n",
    "    Bayesian_Summary_1[[\"ss\", \"model_data\", \"BF\"]].groupby([\"ss\", \"model_data\"]).sum()\n",
    ")\n",
    "sum_BF.reset_index(level=[\"model_data\", \"ss\"], inplace=True)\n",
    "\n",
    "Bayesian_Summary_2 = pd.merge(\n",
    "    Bayesian_Summary_1, sum_BF, how=\"left\", on=[\"model_data\", \"ss\"]\n",
    ")\n",
    "Bayesian_Summary_2\n",
    "Bayesian_Summary_2[\"model_probability\"] = (\n",
    "    Bayesian_Summary_2.BF_x / Bayesian_Summary_2.BF_y\n",
    ")\n",
    "Bayesian_Summary_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_proba = pd.merge(\n",
    "    Bayesian_Summary_2[[\"model_data\", \"model_fit\", \"ss\", \"model_probability\"]],\n",
    "    model_proba_abc,\n",
    "    how=\"left\",\n",
    "    on=[\"model_data\", \"model_fit\", \"ss\"],\n",
    ").round(2)\n",
    "model_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    pd.pivot_table(\n",
    "        model_proba,\n",
    "        values=[\"model_probability\", \"model_probability_ABC\"],\n",
    "        index=[\"ss\"],\n",
    "        columns=[\"model_fit\"],\n",
    "        aggfunc={\"model_probability\": np.mean, \"model_probability_ABC\": np.mean},\n",
    "    ).to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
